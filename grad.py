# -*- coding: utf-8 -*-
"""Grad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B_wNaJHWPg1XDHOM_T1Q1mnR3kLnYiYZ

### Set Up
"""

# Install oauth - - to allow connection to Google Sheets API

!pip install -q oauth2client

# Install OpenSSL - - to allow connection to Google Sheets API

!pip install -q PyOpenSSL

# Install gspread library - - to allow connection to Google Sheets API

!pip install -q gspread

# Install gspread library - - to allow connection to Google Sheets API

!pip install -q --upgrade gspread

"""### Importing Setup"""

# Install Data Analytics libraries, as well as connectors, into Python

# Google

import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json

# Pandas - this is the main library to create dataframes
import pandas as pd

# NumPy
import numpy as np

# Additional code for connection to Google Sheets API

scopes = [
'https://www.googleapis.com/auth/spreadsheets',
'https://www.googleapis.com/auth/drive'
]

credentials = ServiceAccountCredentials.from_json_keyfile_name("/content/drive/MyDrive/Colab Notebooks/booming-edge-400413-a2e78a510bbd.json", scopes)
gc = gspread.authorize(credentials)

# Load Google Sheets

# Inputs

spreadsheet1 = gc.open("Copy of ED 04-05 (2020-21 - Grad Tracking) KJ.AS.JB - May 16, 2023, 10:48 AM") # this Google Sheet lives in My Drive and has a special API email address added to it as an editor
worksheet1 = spreadsheet1.worksheet("AllData")

spreadsheet2 = gc.open("Copy of ED 04-05 (2021-22 - Grad Tracking) KJ.AS.JB - May 17, 2022, 3:01 PM") # this Google Sheet lives in My Drive and has a special API email address added to it as an editor
worksheet2 = spreadsheet2.worksheet("AllData")

spreadsheet3 = gc.open("Copy of ED 04-05 (2022-23 - Grad Tracking) KM.AS.JB - May 17, 2023, 5:29 PM") # this Google Sheet lives in My Drive and has a special API email address added to it as an editor
worksheet3 = spreadsheet3.worksheet("Anonymized_All_Data")

spreadsheet4 = gc.open("Feed list for SoC") # this Google Sheet lives in My Drive and has a special API email address added to it as an editor
worksheet4 = spreadsheet4.worksheet("anonymized")

spreadsheet5 = gc.open("ED 04-05 (2023-24 - Grad Tracking) KM.AS.JB") # this Google Sheet lives in My Drive and has a special API email address added to it as an editor
worksheet5 = spreadsheet5.worksheet("Anonymized_All_Data")

spreadsheet6 = gc.open("2023-24 Student List") # this Google Sheet lives in My Drive and has a special API email address added to it as an editor
worksheet6 = spreadsheet6.worksheet("Grades")

spreadsheet7 = gc.open("ED 04-05 (2023-24 - Grad Tracking) KM.AS.JB") # this Google Sheet lives in My Drive and has a special API email address added to it as an editor
worksheet7 = spreadsheet7.worksheet("Schools")

spreadsheet8 = gc.open("2023-24 Student List") # this Google Sheet lives in My Drive and has a special API email address added to it as an editor
worksheet8 = spreadsheet8.worksheet("2021 and 2022")

# Output Sheet - this Sheet then goes into Looker

spreadsheet99 = gc.open("Grad Outputs") # this Google Sheet lives in My Drive and has a special API email address added to it as an editor
worksheet2023_24_05 = spreadsheet99.worksheet("May 2023-24")

# Create New DataFrames from Imported Data

df_2020_21_may = pd.DataFrame(worksheet1.get_all_records())
df_2021_22_may = pd.DataFrame(worksheet2.get_all_records())
df_2022_23_may = pd.DataFrame(worksheet3.get_all_records())
df_2022_23_bd = pd.DataFrame(worksheet4.get_all_records())
df_2023_24_may = pd.DataFrame(worksheet5.get_all_records())
df_2023_24_bd = pd.DataFrame(worksheet6.get_all_records())
df_ranks = pd.DataFrame(worksheet7.get_all_records())
df_uid = pd.DataFrame(worksheet8.get_all_records())

"""### Initial Data Restructuring - Selecting Columns and Joining additional data columns to make each year's dataset complete"""

# Rename Columns

df_2020_21_may.rename(columns={'Decision':'Initial Offer','Boarding':'Boarding or day'},inplace=True)

df_uid

# Select Columns

df_uid['Student'] = df_uid['Last name'] + ", " + df_uid['First name']
df_uid_2020_21 = df_uid[df_uid['Graduation year']==2021][['Student','User ID']]
df_uid_2021_22 = df_uid[df_uid['Graduation year']==2022][['Student','User ID']]

merged_df_2020_21_may = pd.merge(left=df_2020_21_may,right=df_uid_2020_21,on='Student',how='inner')

merged_df_2020_21_may['User ID'].isnull().value_counts()

# Select Columns

df_2020_21_may = merged_df_2020_21_may[['User ID','Initial Offer','Application Type','Attending','School','School Location','Program Category','Scholarship','Scholarship Type','Scholarship Name','Scholarship Value','Boarding or day']].copy()

# Rename Columns

df_2021_22_may.rename(columns={'Decision':'Initial Offer','Boarding or Day':'Boarding or day'},inplace=True)

merged_df_2021_22_may = pd.merge(left=df_2021_22_may,right=df_uid_2021_22,on='Student',how='inner')

merged_df_2021_22_may['User ID'].isnull().value_counts()

# Select Columns

df_2021_22_may = merged_df_2021_22_may[['User ID', 'Initial Offer','Application Type','Attending','School','School Location','Program Category','Scholarship','Scholarship Type','Scholarship Name','Scholarship Value','Boarding or day']].copy()

# Select Columns

df_2022_23_bd = df_2022_23_bd[['User ID','Boarding or day']].copy()

# Inner Join

merged_df_2022_23_may = pd.merge(left=df_2022_23_may,right=df_2022_23_bd,on='User ID',how='inner')

# Select Columns

df_2023_24_bd = df_2023_24_bd[['User ID','Boarding Or Day']].copy()

# Inner Join

merged_df_2023_24_may = pd.merge(left=df_2023_24_may,right=df_2023_24_bd,on='User ID',how='inner')

# Rename Columns

merged_df_2022_23_may.rename(columns={'Boarding or Day':'Boarding or day'},inplace=True)

# Select Columns

df_2022_23_may = merged_df_2022_23_may[['User ID', 'Initial Offer','Application Type','Attending','School','School Location','Program Category','Scholarship','Scholarship Type','Scholarship Name','Scholarship Value','Boarding or day']].copy()

# Rename Columns

merged_df_2023_24_may.rename(columns={'Boarding Or Day':'Boarding or day'},inplace=True)

# Select Columns

df_2023_24_may = merged_df_2023_24_may[['User ID', 'Initial Offer','Application Type','Attending','School','School Location','Program Category','Scholarship','Scholarship Type','Scholarship Name','Scholarship Value','Boarding or day']].copy()

# Add Columns for Year

df_2020_21_may['Year'] = '2020-21'
df_2021_22_may['Year'] = '2021-22'
df_2022_23_may['Year'] = '2022-23'
df_2023_24_may['Year'] = '2023-24'

# Concatenate All DataFrames

df = pd.concat([df_2020_21_may,df_2021_22_may,df_2022_23_may,df_2023_24_may])

# Select Columns

df_ranks = df_ranks[['School','Highly Selective','2023-24 Admit Rates']].copy()

# Add Highly Selective Column based on School

rank_mapping = df_ranks.set_index('School')['Highly Selective']

# Map 'Rank' values to df using the 'School' column

df['Highly Selective'] = df['School'].map(rank_mapping)

# Add Admit Rate Column based on School

rank_mapping = df_ranks.set_index('School')['2023-24 Admit Rates']

# Map 'Rank' values to df using the 'School' column

df['Admit Rate'] = df['School'].map(rank_mapping)

"""### Cleaning and Imputing - By Column"""

# Initial Offer - Fill empty cells

df.loc[(df['Initial Offer'] == ''), 'Initial Offer'] = 'None'

# Application Type - part 1 of 2 - Fill empty cells

df.loc[(df['School Location'].str.contains('Canada')) & (df['Application Type'] == ''), 'Application Type'] = 'CDN'
df.loc[(df['School Location'].str.contains('USA')) & (df['Application Type'] == ''), 'Application Type'] = 'RD'
df.loc[(df['School Location'].str.contains('UK')) & (df['Application Type'] == ''), 'Application Type'] = 'UK Regular'
df.loc[(df['Application Type'] == ''), 'Application Type'] = 'Other'

# Application Type - part 2 of 2 - Create new Column called 'Application Type Detail' with more detail


df.loc[df['Application Type'].str.contains('EA'), 'Application Type Detail'] = 'US Early Action (Not Binding)'
df.loc[df['Application Type'].str.contains('ED I'), 'Application Type Detail'] = 'US Early Decision I (Binding)'
df.loc[df['Application Type'].str.contains('ED II'), 'Application Type Detail'] = 'US Early Decision II (Binding)'
df.loc[df['Application Type'].str.contains('RD'), 'Application Type Detail'] = 'US Regular Decision (Not Binding)'
df.loc[df['Application Type'].str.contains('REA'), 'Application Type Detail'] = 'US Restricted Early Action (Not Binding)'
df.loc[df['Application Type'].str.contains('UK Early'), 'Application Type Detail'] = 'UK Early'
df.loc[df['Application Type'].str.contains('UK Regular'), 'Application Type Detail'] = 'UK Regular'
df.loc[df['Application Type'].str.contains('CDN'), 'Application Type Detail'] = 'Canada'
df.loc[df['Application Type'].str.contains('Ireland'), 'Application Type Detail'] = 'Ireland'

# Scholarship Value - part 1 of 3 - Remove Dollar Sign and Commas

df['Scholarship Value Converted'] = df['Scholarship Value'].replace('', '0').replace('[\$,]', '', regex=True).astype(float)
df['Scholarship Value Converted'].fillna(0, inplace=True)

# Scholarship Value - part 2 of 3 - Establish currency exchange rates

conversion_rate_gbp = 1.67
conversion_rate_usd = 1.34

# Scholarship Value - part 3 of 3 - convert currency

def convert_currency(row):
    if 'USA' in row['School Location']:
        return row['Scholarship Value Converted'] * conversion_rate_usd
    elif 'UK' in row['School Location']:
        return row['Scholarship Value Converted'] * conversion_rate_gbp
    elif 'Ireland' in row['School Location']:
        return row['Scholarship Value Converted'] * conversion_rate_gbp
    else:
        return row['Scholarship Value Converted']


df['Scholarship Value Converted'] = df.apply(convert_currency, axis=1)

# Boarding or day - Rename all to the same

replacement_map = {'B': 'Boarding', 'D': 'Day'}
df['Boarding or day'] = df['Boarding or day'].replace(replacement_map)

# Highly Selective - Fill empty cells

df['Highly Selective'].replace('',0, inplace=True)

# School Location Simplified - Create new column without provinces

df['School Location Simplified'] = 'International'

df.loc[df['School Location'].str.contains('Canada'), 'School Location Simplified'] = 'Canada'
df.loc[df['School Location'].str.contains('US'), 'School Location Simplified'] = 'USA'
df.loc[df['School Location'].str.contains('UK'), 'School Location Simplified'] = 'UK'
df.loc[df['School Location'].str.contains('Ireland'), 'School Location Simplified'] = 'Ireland'

# Success Rate - Calculate success rate to verify results in Looker

df['Offer Count'] = df['Initial Offer'].apply(lambda x: 1 if x == 'Offer' else 0)

grouped = df.groupby(['Year', 'School Location Simplified']).agg(
    total_applications=pd.NamedAgg(column='School Location Simplified', aggfunc='count'),
    total_offers=pd.NamedAgg(column='Offer Count', aggfunc='sum')
)
grouped['Success Rate'] = grouped['total_offers'] / grouped['total_applications']

# Average Number of Applications Per Student

# Calculate the count of each 'User ID'
df['Count'] = df.groupby('User ID')['User ID'].transform('size')

# Identify the first occurrence of each 'User ID'
df['first_occurrence'] = df.duplicated('User ID')


# Replace counts in all but the first occurrence with 0
df.loc[df['first_occurrence'], 'Count'] = np.nan

# Optionally, drop the helper column 'first_occurrence' if no longer needed
#df.drop('first_occurrence', axis=1, inplace=True)

# School Simplified

df['School Simplified'] = df['School'].str.split(' -').str[0]

# All Canadian Schools

df_offers = df[(df['Initial Offer']=='Offer') & (df['School Location Simplified']=='Canada') & (df['Year']=='2023-24')]

result = df_offers.groupby('School Simplified').size()

result_df = result.reset_index()
result_df.columns = ['School', 'Count']  # Renaming columns for clarity

formatted_string = ', '.join(f"{row['School']} ({row['Count']})" for index, row in result_df.iterrows())

# Adding this formatted string as a new column in the original DataFrame
df['All Canadian Offers'] = formatted_string

# Identify the first occurrence of each 'User ID'
df['first_occurrence_2'] = df.duplicated('All Canadian Offers')


# Replace counts in all but the first occurrence with 0
df.loc[df['first_occurrence_2'], 'All Canadian Offers'] = np.nan

df['All Canadian Offers'].unique()

df

df['All Canadian Offers'].value_counts()

df = df.fillna(0) # Fill NaN cells before write back to Google Sheet output

# Show me final DataFrame before exporting
df

# WriteBack to Sheets

worksheet2023_24_05.update([df.columns.values.tolist()] + df.values.tolist())

